{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbcfff26",
   "metadata": {},
   "source": [
    "### There are following types of metrics:\n",
    "* MAE (mean absolute error)\n",
    "* MSE (mean square error)\n",
    "* RMSE (root mean square error)\n",
    "* R2-SCORE \n",
    "* ADJUSTED R2-SCORE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959a8e40",
   "metadata": {},
   "source": [
    "# 1.***MAE***\n",
    "Mean Absolute Error is a model evaluation metric used with regression models. The mean absolute error of a model with respect to a test set is the mean of the absolute values of the individual prediction errors on over all instances in the test set.\n",
    "\n",
    "<img title=\"Mean Absolute Error\" src=\"images/mean_absolute_error.svg\" height=400 width=400 />\n",
    "Here xi is the predicted value like y^ (y hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b306051c",
   "metadata": {},
   "source": [
    "### Advantages\n",
    "* Unit of the output doesn't change. (it remain same)\n",
    "* Robust to outliers (outliers not impact on that much more)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230f9451",
   "metadata": {},
   "source": [
    "### Disadvantage\n",
    "* It's graph is not differntiable at zero. so when we apply many optimization in which we apply like gradient descent in which we take the term as equal to zero and then defferntiate it.So it doesn't work in that confition.That is a biggest restriction that we have with MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1909ba",
   "metadata": {},
   "source": [
    "# 2.***MSE***\n",
    "The Mean Squared Error (MSE) is a measure of how close a fitted line is to data points. For every data point, you take the distance vertically from the point to the corresponding y value on the curve fit (the error), and square the value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424af518",
   "metadata": {},
   "source": [
    "<img title=\"Mean Squared Error\" src=\"images/mean_squared_error.svg\" height=400 width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8e5ee9",
   "metadata": {},
   "source": [
    "The main difference in between **MAE** and **MSE** is that MSE graph is differentialbe at zero. because in it we use square instead of mod."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83889289",
   "metadata": {},
   "source": [
    "### Advantage\n",
    "* We can use it as a lose function because it is defferentiable at zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b7d4aa",
   "metadata": {},
   "source": [
    "### Disadvantage\n",
    "* The unit of output should be in square form.\n",
    "* Not Robust to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156f76dc",
   "metadata": {},
   "source": [
    "# 3.RMSE\n",
    "It's a square root of MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff5d6f6",
   "metadata": {},
   "source": [
    "<img title=\"Root Mean Squared Error\" src=\"images/root_mean_square_deviation.svg\" height=400 width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182b3ed6",
   "metadata": {},
   "source": [
    "It has only one benifit greater than MSE which is that it's output will be in same unit (Unit remain same)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb70409d",
   "metadata": {},
   "source": [
    "Otherwise it's all advantage and disadvantages are same as MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2571e02f",
   "metadata": {},
   "source": [
    "***MAE MSE RMSE these all are loss function who's tells us the error about the model.*** and these are depend on context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5084f247",
   "metadata": {},
   "source": [
    "# 4.R2-score (R2 OR Coefficient of Determination)\n",
    "The coefficient of determination is a measurement used to explain how much variability of one factor can be caused by its relationship to another related factor. This correlation, known as the \"goodness of fit,\" is represented as a value between 0.0 and 1.0.\n",
    "<img title='R square' src='images/coefficient_of_determination.svg' height=400 width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16d79f8",
   "metadata": {},
   "source": [
    "<img title='Coefficient of Determination' src='images/R2-score.png' height=600 width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba93e53",
   "metadata": {},
   "source": [
    "In this scenario what i do is. Suppose i have no input i have just only one output feature called as package (salary). So how can find the package for any person? i just take the previous data of package and take the mean of all rows and this is my answer. But it is not so much good so what i do in the R2 score i just compare the mean scenario with regression line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a132249b",
   "metadata": {},
   "source": [
    "* what if the value of r2 score becomes 0? so what that mean? the mean is that the dependency of my independent feature is zero.it's not require.In simple term its mean that my value which i get by taking mean of package feature is equal to the regression line (predicted line) so if i can got the equal value without using independent feature (cgpa) so there is no need of that feature.\n",
    "* And what is happen when my R2 score value becomes 1? Its means that my R2 score values is correct its not doing any mistake.\n",
    "\n",
    "* So in simple words when the value of **R2** is near to 1 it is good and when it is near to 0 it is bad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94958a64",
   "metadata": {},
   "source": [
    "# 5. Adjusted R2 score\n",
    "* In **R2** score there is a **Disadvantage** is that would give the deception.When we increase the amount of features then the value of R2 score become increase Which is not good it shows that it is clearly a deceptive.So In that case we use an update version of R2 known as **Adjusted R2 score** (adjusted r square).\n",
    "* Adjusted R-squared is a modified version of R-squared that has been adjusted for the number of predictors in the model. The adjusted R-squared increases when the new term improves the model more than would be expected by chance. It decreases when a predictor improves the model by less than expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06396bc",
   "metadata": {},
   "source": [
    "<img title='Adjusted R Square' src='images/adjusted r2 score.png' height=400 width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071a2929",
   "metadata": {},
   "source": [
    "* **n = number of rows**\n",
    "* **k = number of columns**\n",
    "* **R2 = Simple Coefficient of Determination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7029242c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
